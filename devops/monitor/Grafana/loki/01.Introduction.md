Loki là một hệ thống logging stack với horizontally-scalable,  highly-available, multi-tenant log được lấy cảm hứng từ Prometheus.

Loki khác Prometheus là tập trung trên logs thay vì metrics, và tập hợp logs thông qua push chứ không phải pull như Prometheus

Loki không có index cho nội dung của logs, nó chỉ có index cho metadata về logs của bạn dưới dạng tập hợp các labels cho mỗi luồng log

Một Log Stream là tập hợp các log được chia sẻ cùng labels, labels giúp cho loki tìm một log stream trong data store của bạn, vì vậy có một tập hợp labels chất lượng là chìa khóa của sự query hiệu quả

Log data sau đó được đóng gói và lưu trữ thành những phần nhỏ trong một object store  như Amazon Simple Storage Service (S3), Google Cloud Storage (GCS),...

![image.png](https://grafana.com/docs/loki/latest/get-started/loki-overview-2.png)

Thông thường, Loki-based logging stack bao gồm 3 thành phần:

+ Agent
  + một agent hoặc một client, ví dụ Grafana Alloy, hoặc Promtail, được distributed với Loki, agent thu thập các log, biến log thành stream bằng cách thêm labels, và push streams thông qua Http API cho Loki
+ Loki
  + main server, chịu trách nhiệm nhập và lưu trữ nhật ký cũng như xử lý các truy vấn.
+ Grafana
  + Query và hiển thị log data.

## Chạy Loki locally

Ta có thể khởi chạy Loki bằng Docker Compose, nó được cấu hình bao gồm những thành phần sau, mỗi thành phần trong container của chính nó:

+ flog : là một sample app để tạo log lines, nó là log generator cho common log formats.
+ Grafana Alloy: scrapes log lines từ flog và push chúng cho Loki thông qua gateway
+ Gateway (NGINX) nhận requests và chuyển chúng cho container thích hợp dựa trên request’s URL.
+ Một Loki read component (Query Fronted, Querier)
+ Một Loki write component (Distributor, Ingester)
+ Một  Loki backend component (Index Gateway, Compactor, Ruler, Bloom Compactor (Experimental), Bloom Gateway (Experimental))
+ Minio : nơi Loki lưu trữ index và chunks của nó
+ Grafana

![image.png](https://grafana.com/media/docs/loki/get-started-flog-v3.png)

## Loki architecture

### Architecture

Grafana Loki có kiến trúc dựa trên microservices được thiết kế phát triển theo chiều ngang và phân tán

Hệ thống có nhiều thành phần có thể chạy song song

 Grafana Loki’s thiết kế chạy tất cả thành phần trong một binary  hoặc Docker image

 Để bắt đầu nhanh, chạy Grafana Loki trong  “single binary” mode cho tất cả các thành phần chạy đồng thời trong một process hoặc trong “simple scalable deployment”  nhóm các thành phần read, write, và backend parts.

 ![image.png](https://grafana.com/docs/loki/latest/get-started/loki_architecture_components.svg)

### Storage

### Data format

Grafana Loki có hai loại file chính là index và chunks

+ Index là một bảng nội dung xác định vị trí của các log dựa trên các nhãn cụ thể.
+ Chunks là các container chứa các mục log cho một tập nhãn cụ thể.

![image.png](https://grafana.com/docs/loki/latest/get-started/chunks_diagram.png)

### Index format

+ TSDB (recommended)

### Chunk format

Chunk là một container chứa các dòng log của một stream (tập hợp nhãn duy nhất) trong một khoảng thời gian cụ thể.  Nó giúp gom nhóm các log có cùng nhãn trong một khoảng thời gian xác định, giúp tối ưu hóa việc lưu trữ và truy xuất log.

### Block format

 Block là một tập hợp các entry, mỗi entry là một dòng log riêng lẻ. Các byte của block được lưu trữ ở dạng nén.

### Write path

1. Receiving Data:
Distributor: Nhận HTTP POST với streams và log lines.

2. Hashing and Routing:
Distributor: Hash mỗi stream để xác định ingester phù hợp dựa trên consistent hash ring.

3. Sending to Ingesters:
Distributor: Gửi mỗi stream tới ingester và các bản sao của nó (theo replication factor cấu hình).
Processing by Ingester:

4. Ingester: Nhận stream, tạo chunk mới hoặc thêm vào chunk hiện có cho dữ liệu của stream.
Acknowledgment: Ingester xác nhận ghi dữ liệu.

5. Distributor Confirmation:
Distributor: Chờ đa số (quorum) các ingester xác nhận ghi dữ liệu.

6. Response: Trả về thành công (mã trạng thái 2xx) nếu nhận được đủ quorum xác nhận, hoặc lỗi (mã trạng thái 4xx hoặc 5xx) nếu ghi dữ liệu thất bại.

### Read path

1. Receiving Query:

Query Frontend: Nhận HTTP GET với LogQL query.

2. Splitting and Scheduling:

Query Frontend: Chia nhỏ query thành sub-queries và chuyển chúng đến query scheduler.

3. Processing by Querier:

Querier: Kéo sub-queries từ scheduler.
Ingesters: Nhận và xử lý query trong bộ nhớ.
Querier: Tải dữ liệu từ backing store nếu ingesters không có đủ dữ liệu.

4. Deduplication and Merging:

Querier: Lọc bỏ trùng lặp và trả về kết quả của sub-query.
Query Frontend: Chờ tất cả sub-queries hoàn thành, hợp nhất kết quả cuối cùng và trả về cho client.

## Loki components

### Distributor

Chịu trách nhiệm xử lý requests push đến từ clients.

Một distributor nhận một tập hợp của streams trong một HTTP request,  mỗi stream được xác thực về tính chính xác và đảm bảo nó giới hạn là tenant hay global.

Sau đó, mỗi stream hợp lệ sẽ được gửi đến n  ingesters một cách song song, n ở đây phụ thuộc vào cấu hình replica data. Distributor xác định ingesters mà nó gửi đến bằng cách sử dụng  consistent hashing.

Distributor là stateless component. Nó chỉ đơn giản thực hiện scale hoặc offload khối lượng công việc đến ingesters. Khả năng hoạt động độc lập của Loki có thể giúp bảo vệ những tấn công đến ingesters trong trường hợp overload và cũng dễ dàng sử dụng replica

#### Validation

Đảm bảo dữ liệu đến đều hợp lệ, ví dụ:

+ Labels: Kiểm tra nhãn xem có hợp lệ theo chuẩn của Prometheus hay không.
+ Timestamps: Đảm bảo dấu thời gian không quá cũ hoặc quá mới.
+ Log Length: Đảm bảo các dòng log không quá dài.

#### Preprocessing

Hiện tại, cách duy nhất mà distributor  thay đổi dữ liệu đến là chuẩn hóa nhãn. Điều này có nghĩa là làm cho {foo="bar", bazz="buzz"} tương đương với {bazz="buzz", foo="bar"} hay nói cách khác là sắp xếp các nhãn.

#### Rate limiting

Distributor cũng có thể rate limit logs đến giúp cụm hoạt động hiệu quả và an toàn.

### Forwarding

#### Replication factor

Để giảm thiểu việc mất mác dữ liệu, ingester thường được replication thành 3.

Cụ thể, đối với mỗi tập hợp nhãn (gọi là stream) được gửi đến một distributor, distributor sẽ băm các nhãn và sử dụng giá trị băm được để tra cứu các ingester theo hệ số sao chép trong vòng (ring, một thành phần phụ trách bảng băm phân tán).

 Sau đó, distributor sẽ cố gắng ghi cùng một dữ liệu vào tất cả các ingester đó trong cùng ring. Quá trình này sẽ sinh ra lỗi nếu số lần ghi thành công ít hơn một quorum (quorum). Quorum được định nghĩa là floor( replication_factor / 2 ) + 1. Vì vậy, với hệ số sao chép là 3, chúng ta yêu cầu ít nhất hai lần ghi thành công. Nếu ít hơn hai lần ghi thành công, distributor sẽ trả về lỗi và thao tác ghi sẽ được thử lại.

Nếu một ghi chép được xác nhận bởi 2 trong số 3 ingesters, chúng ta có thể chịu đựng việc mất một ingester nhưng không phải hai, vì điều này sẽ dẫn đến mất dữ liệu.

Hệ số sao chép không phải là yếu tố duy nhất ngăn chặn việc mất dữ liệu; mục đích chính của nó là cho phép các ghi chép tiếp tục không bị gián đoạn trong suốt quá trình triển khai và khởi động lại. Thành phần ingester hiện bao gồm một nhật ký ghi trước (WAL) lưu trữ các ghi chép đến đĩa để đảm bảo chúng không bị mất miễn là đĩa không bị hỏng. Sự kết hợp của hệ số sao chép và WAL đảm bảo dữ liệu không bị mất trừ khi xảy ra thất bại nghiêm trọng trong cả hai cơ chế (tức là nhiều ingester gặp sự cố và mất/hỏng đĩa của chúng).

#### Hashing

Distributors sử dụng consistent hashing kết hợp với cấu hình replication factor để định nghĩa các   instances của ingester nên nhận dữ liệu stream.

Một stream là tập hợp các logs có liên quan như cùng một tenant hoặc label duy nhất. Stream sau đó được hash bằng tenant ID và tập hợp các label, mã hash này được sử dụng để tìm các ingesters để gửi stream đến.

Một hash ring, được duy trì bằng giao thức P2P sử dụng Memberlist protocol, hoặc lưu trữ trong một key-value store như Consul được sử dụng để đạt được sự nhất quán, tất cả ingesters đăng ký vào hash ring với tokens mà chúng sở hữu. Mỗi token là một số unsigned 32-bit ngẫu nhiên.

Cùng với tokens, ingester đăng ký trạng thái của chúng vào hash ring. Trạng thái JOIN và ACTIVE có thể nhận tất cả write requests, trong khi ACTIVE và LEAVING có thể nhận read requests.

Khi thực hiện tra cứu hash, distributors chỉ sử dụng tokens cho ingester ở trạng thái thích hợp cho mỗi request.

Để tra cứu hash, distributors tìm token thích hợp nhỏ nhất lớn hơn hash của stream. Khi hệ thống yêu cầu replication factor lớn hơn 1 (có nghĩa là mỗi log entry cần được sao lưu nhiều lần), distributor sẽ không chỉ tìm một token. Thay vào đó, nó sẽ tìm các token kế tiếp theo chiều kim đồng hồ trong hash ring mà thuộc về các ingester khác nhau.

Hiệu quả của việc thiết lập này là mỗi token trong một ingester sở hữu sẽ chịu trách nhiệm cho một phạm vi của hashes.

Ví dụ: nếu có 3 tokens với giá trị 0, 25 và 50, giá trị hash = 3 thì sẽ được gán cho ingester 25

#### Quorum consistency

Vì tất cả distributors chia sẻ truy cập chung với cùng hash ring, write requests có thể được gửi đến bất kỳ distributor nào.

Để đảm bảo kết quả query được consistent, Loki sử dụng Dynamo-style quorum trên read và   writes.

### Ingester

Ingesters chứa một  lifecycler để quản lý  lifecycle của một ingester trong hash ring. Mỗi ingester có một trong những trạng thái sau:

PENDING, JOINING, ACTIVE, LEAVING hoặc UNHEALTHY

+ PENDING: là một trạng thái khi nó chờ đợi một handoff từ một ingester khác khi nó LEAVING. Điều này chỉ áp dụng cho legacy deployment modes.
+ JOINING : trạng thái khi nó hiện tại chèn tokens vào ring và tự khởi tạo. Nó có thể nhận được yêu cầu ghi cho các token mà nó sở hữu.
+ ACTIVE : khởi tạo hoàn tất, nó nhận cả write và read request.
+ LEAVING : trạng thái shutdown, nhận được read khi dữ liệu vẫn còn trong bộ nhớ
+ UNHEALTHY

Mỗi log stream mà ingester nhận sẽ build up thành một tập hợp nhiều "chunks" trong bộ nhớ và chuyển sang backing storage theo khoảng time có thể cấu hình

Chunks được nén và đánh dấu chỉ đọc khi:

+ Chunk hiện tại đã đạt được capacity (theo cấu hình)
+ Quá nhiều thời gian trôi qua mà chunk ko được update
+ Một flush xảy ra

Bất cứ khi nào chunk được nén và được đánh dấu là chỉ đọc, một writable chunk sẽ thay thế nó.

Nếu ingester bị crash hoặc dừng đột ngột, dữ liệu chưa được flushed sẽ mất.

Khi một flush vào một persistent storage xảy ra, chunk được hash dựa trên tenant, labels và content của nó. Nghĩa là nhiều ingester có cùng dữ liệu được copy sẽ không được lưu hai lần vào backing store, nhưng nếu bất kỳ write failed cho một replicas, nhiều  chunk objects khác nhau sẽ được tạo trong  backing store.

### Timestamp Ordering

### Handoff

### Filesystem support

### Query frontend

Query frontend là một  optional service cung cấp querier’s API endpoints có thể sử dụng để read path nhanh chóng. Khi query frontend sử dụng, incoming query requests sẽ chuyển hướng trực tiếp đến query frontend thay vì queriers.

Query frontend thực hiện một số chỉnh sửa với query và giữ queries trong một queue nội bộ,  queriers có công việc pull jobs từ queue , thực thi chúng và trả chúng về cho query frontend để thực hiện tổng hợp.

Queriers cần cấu hình với query frontend address thông qua (-querier.frontend-address ).

Nó là stateless. Do cách hoạt động của queue nội bộ, nên có query frontend replicas để tận dụng lợi thế của việc lập lịch, thường 2 là đủ
#### Queueing
Nếu  query scheduler component không sử dụng, query frontend  cũng thực hiện query queueing:

- Truy Vấn Lớn và Out-of-Memory (OOM): Khi một truy vấn lớn có thể gây ra lỗi out-of-memory (OOM) trong querier (quá trình xử lý truy vấn), hệ thống sẽ thử lại truy vấn đó khi gặp lỗi.
  - Lợi Ích: Điều này cho phép quản trị viên có thể cấu hình bộ nhớ ít hơn cho các truy vấn hoặc chạy nhiều truy vấn nhỏ hơn song song, giúp giảm chi phí tổng thể (TCO).

- Phân Phối Truy Vấn: Để ngăn chặn việc nhiều truy vấn lớn cùng được gửi đến một querier duy nhất, Loki phân phối các truy vấn lớn qua tất cả các queriers bằng cách sử dụng hàng đợi FIFO (first-in/first-out).
  - FIFO: Nguyên tắc FIFO đảm bảo rằng các truy vấn sẽ được xử lý theo thứ tự chúng đến, giúp tránh việc một querier phải xử lý quá nhiều truy vấn lớn cùng lúc.

- Lịch Trình Công Bằng: Để ngăn chặn một tenant (khách hàng) gây từ chối dịch vụ (Denial-of-Service - DOS) cho các tenant khác, Loki thực hiện việc lập lịch truy vấn một cách công bằng giữa các tenant.
  - Công Bằng: Việc phân phối truy vấn và sử dụng hàng đợi giúp đảm bảo rằng không có tenant nào có thể làm ảnh hưởng tiêu cực đến hiệu suất của các tenant khác bằng cách gửi quá nhiều truy vấn hoặc truy vấn quá lớn.

#### Splitting
- Tách Truy Vấn: Chia truy vấn lớn thành nhiều truy vấn nhỏ.
- Thực Thi Song Song: Xử lý các truy vấn nhỏ song song trên các queriers hạ nguồn.
- Ghép Kết Quả: Kết hợp các kết quả từ các truy vấn nhỏ để tạo ra kết quả cho truy vấn gốc.
- Lợi Ích: Ngăn ngừa lỗi OOM, tăng tốc độ xử lý và cải thiện hiệu suất hệ thống.

#### Caching
##### Metric queries
- Lưu Kết Quả Truy Vấn: Kết quả của các truy vấn metric được lưu trữ trong bộ nhớ cache để có thể tái sử dụng cho các truy vấn sau.
- Truy Vấn Không Đầy Đủ: Nếu kết quả từ cache không đầy đủ, query frontend sẽ tính toán các truy vấn con cần thiết và thực thi chúng song song trên các downstream queriers.
- Cải Thiện Tính Cacheable: Query frontend có thể căn chỉnh các truy vấn với tham số theo bước để cải thiện khả năng cache của kết quả truy vấn.
- Tương Thích Với Backend Caching: Bộ nhớ cache kết quả truy vấn tương thích với các backend caching như Memcached, Redis và bộ nhớ cache trong bộ nhớ (in-memory cache).
##### Log queries
Negative Cache là một cơ chế caching trong query frontend của Loki.
- Cache Kết Quả Âm: Thay vì lưu trữ các kết quả truy vấn log thực tế, negative cache lưu trữ thông tin về các khoảng thời gian không có kết quả (khoảng thời gian mà không có dòng log nào được tìm thấy).
- Negative cache hiệu quả hơn việc lưu trữ các kết quả log thực tế vì:
  - Giới Hạn Kết Quả: Các truy vấn log thường có giới hạn số lượng kết quả (thường là 1000 kết quả).
  - Truy Vấn Dài: Khi bạn thực hiện một truy vấn trên khoảng thời gian dài mà chỉ tìm thấy vài dòng log, nếu chỉ lưu trữ các kết quả thực tế, bạn vẫn phải xử lý một lượng dữ liệu lớn để xác minh rằng không có kết quả khác.
- Tiết Kiệm Tài Nguyên:
  - Bằng cách chỉ lưu trữ thông tin về các khoảng thời gian không có kết quả, negative cache giúp tiết kiệm tài nguyên lưu trữ và giảm khối lượng dữ liệu cần xử lý.

##### Index stats queries

### Log volume queries

### Query scheduler

### Querier

### Index Gateway

### Compactor

### Ruler

### Bloom Compactor

### Bloom Gateway
