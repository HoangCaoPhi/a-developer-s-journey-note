# Labels
Labels là cặp giá trị key-value có thể định nghĩa bất kỳ thứ gì. Chúng còn được coi là metadata để mô tả một log stream.

Scrape configs được cung cấp với  Grafana Loki cũng định nghĩa labels này.

Labels trong Loki thực hiện công việc rất quan trọng: chúng xác định một stream, Cụ thể hơn, sự kết hợp của mọi  label key và giá trị của nó xác định ra stream. Nếu chỉ có một label value thay đổi, nó cũng tạo stream mới

Nếu quen thuộc Prometheus thì có thể đã quen với thuật ngữ series, tuy nhiên Prometheus có bổ sung một thứ là  metric name. Loki ko có metric name, nó chỉ có labels, và sử dụng stream thay vì series.

Structured metadata không định nghĩa một stream, nó là metadata được attached vào một log file.

Labels là index cho Loki’s log data. Chúng thường sử dụng để tìm compressed log content, được lữu trữ thành các chunks. Mọi sự kết hợp của label và value tạo thành một stream, và logs cho mỗi stream đã được nhóm lại, nén và lưu trữ dưới dạng chunks.

## Format

Label name:
    - Chỉ được chứa ASCII letters, số, dấu gạch dưới và dấu hai chấm, phải khớp với regex: [a-zA-Z_:][a-zA-Z0-9_:]*.
    - Dấu hai chấm dành riêng cho các quy tắc do người dùng xác định. Chúng không nên sử dụng bởi các exporters và direct instrumentation.
    - Các ký tự không được hỗ trợ phải chuyển thành dấu _, ví dụ app.kubernetes.io/name => app_kubernetes_io_name

## Cardinality

Cardinality: Số lượng tổ hợp duy nhất của các label và giá trị. Cardinality cao có thể gây ra vấn đề hiệu suất và chi phí.

Việc quản lý cardinality là rất quan trọng để đảm bảo Loki hoạt động hiệu quả và tiết kiệm chi phí. Bạn nên cân nhắc kỹ lưỡng khi thiết lập labels để tránh gây ra cardinality quá cao.

## Optimal Loki performance with parallelization

Một trong những ưu điểm của Loki’s là khả năng chia các queies thành các queries nhỏ hơn và gửi chúng đi một cách song song, vì vậy bạn có thể truy vấn lượng lớn dữ liệu logs trong khoảng thời gian ngắn.

Chỉ mục lớn thường phức tạp và chi phí cao, thông thường một full-text index của dữ liệu log của bạn có thể tương đương size hoặc lớn hơn chính dữ liệu log đó. Để query log data, index cần được loaded và về hiệu năng, nó cũng chiếm bộ nhớ. Điều này rất khó scale và khi thu thập nhiều logs hơn, indexs trở nên ngày càng lớn.

Bây giờ hãy nói về Loki, trong đó index thường nhỏ hơn một bậc so với khối lượng logs bạn đã thu thập. Vì vậy nếu bạn làm tốt việc quản lý stream, thì index sẽ nhỏ hơn rất nhiều so với dữ liệu log thu thập.

Chỉ mục nhỏ hơn của Loki giữ chi phí cố định thấp hơn, trong khi bạn có thể điều chỉnh hiệu suất truy vấn thông qua việc mở rộng theo chiều ngang.

Ví dụ:

Giả sử bạn muốn truy vấn các log từ một địa chỉ IP cụ thể. Thay vì sử dụng một nhãn để lưu trữ địa chỉ IP, điều này sẽ làm tăng độ cardinality và tạo nhiều luồng (streams), bạn có thể sử dụng một biểu thức lọc:

```{job="apache"} |= "11.11.11.11"```

Lọc: Loki áp dụng biểu thức lọc vào nội dung log, tìm kiếm các kết quả phù hợp trên các phân mảnh dữ liệu. Điều này tránh vấn đề độ cardinality cao liên quan đến việc lưu trữ mọi giá trị có thể như một nhãn.

LUồng hoạt động: Loki sẽ chia query thành các phần nhỏ hơn, và mở mỗi chunk cho các streams để tìm labels phù hợp, sau đó tìm kiếm IP cần lọc.

Với Loki, hiệu suất truy vấn có thể được điều chỉnh dựa trên tài nguyên bạn cấp. Bạn có thể quyết định mức độ sức mạnh truy vấn cần thiết và mở rộng cơ sở hạ tầng tương ứng.

# Structured metadata

Việc giữ low cardinality labels là rất quan trọng, vậy nếu muốn thêm metadata vào logs mà không indexing chúng như label thì Structured metadata là giải pháp cho điều đó.

Structured metadata là cách gắn metadata cho logs mà không indexing chúng hoặc bao gồm chúng trong chính log line. 

Structured metadata cũng có thể sử dụng để query metadata cần thiết mà không cần phải áp dụng một parser ở thời điểm query time.

## Khi nào sử dụng SM
+ Nếu bạn thu thập data trong OpenTelemetry format, sử dụng Grafana Alloy hoặc OpenTelemetry Collector.     Structured metadata được thiết kế hỗ trợ  native ingestion của OpenTelemetry data.

+ Trong trường hợp bạn có metadata với cardinality cao (tức là số lượng giá trị có thể rất lớn hoặc không cố định), và metadata này không xuất hiện trực tiếp trong dòng log, việc sử dụng metadata có cấu trúc sẽ giúp cải thiện hiệu quả quản lý và truy vấn dữ liệu.

## Attaching structured metadata to log lines

Bạn có tùy chọn thêm metadata vào mỗi log lines cùng với mỗi log line và timestamp.

Ví dụ:

```json
"values": [
    [ "<unix epoch in nanoseconds>", "<log line>", {"trace_id": "0242ac120002", "user_id": "superUser123"}]
]
```
## Querying structured metadata

Structured metadata được extracted tự động cho mỗi log line được trả về và gắn vào labels rồi trả về cho query. Bạn có thể sử dụng label của structured metadata để filter log line với label filter expression.

Ví dụ

```json
{job="example"} | pod="myservice-abc1234-56789"
```
